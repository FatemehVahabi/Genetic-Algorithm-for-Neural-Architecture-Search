{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb5300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "from tensorflow.keras.layers import Embedding, Input, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2da02-de1e-4a2a-b9ac-f2a1c276233a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2de32abd-1402-44c1-96d3-7e00e8b1a4c6",
   "metadata": {},
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs\n",
    "        self.output = 1/(1+np.exp(-inputs))\n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input*self.output*(1-self.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a4901-2e69-4bf3-9c9d-0f46dbcb6eb2",
   "metadata": {},
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0,inputs)\n",
    "        self.input = inputs\n",
    "    \n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input\n",
    "        self.b_output[self.input<=0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ef9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, d_model, num_heads,af, neuron_n, dropout_rate,norm_existance):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.layernorm = LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        if len(neuron_n)==0:\n",
    "            self.feedforward = Sequential([Dense(d_model),])\n",
    "        elif len(neuron_n)==1:\n",
    "            self.feedforward = Sequential([Dense(neuron_n[0], activation=af[0]),Dropout(dropout_rate[0]),Dense(d_model),])\n",
    "\n",
    "        else:\n",
    "            self.feedforward = Sequential([Dense(neuron_n[0], activation=af[0]),Dropout(dropout_rate[0]), \n",
    "                                       Dense(neuron_n[1], activation=af[1]),Dropout(dropout_rate[1]),Dense(d_model),])\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        if  norm_existance[0]==1 :\n",
    "            out1 = self.layernorm(inputs + attn_output)\n",
    "        else :\n",
    "            out1 = inputs + attn_output\n",
    "        feedforward_output = self.feedforward(out1)\n",
    "        if  norm_existance[1]==1 :\n",
    "            re = self.layernorm(out1 + feedforward_output)\n",
    "        else:\n",
    "            re = out1 + feedforward_output\n",
    "\n",
    "        return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17724e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, d_model):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=d_model)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc13ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Training sequences\n",
      "25000 Test sequences\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000  # Only consider the top 20k words\n",
    "maxlen = 200  # Only consider the first 200 words of each movie review\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_test), \"Test sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba6801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66870b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters=[num_layeroftrans,num_attentionhead,num_hiddenfeedforward,num_hiddenffn,name_actfunc,num_neuron,prob_drop,d_model,norm_existance]\n",
    "\n",
    "def NeuralNetworkTransformer(chromo):\n",
    "    d_model = chromo[7]   # Embedding size for each token\n",
    "    \n",
    "\n",
    "    inputs = Input(shape=(maxlen,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, d_model)\n",
    "    x = embedding_layer(inputs)\n",
    "    \n",
    "    if chromo[0]==1:\n",
    "        transformer_block1 = TransformerBlock(d_model, chromo[1][0] ,chromo[4][0], chromo[5][0],chromo[6][0],chromo[8][0])\n",
    "        x = transformer_block1(x)\n",
    "        \n",
    "    elif chromo[0]==2:\n",
    "        transformer_block1 = TransformerBlock(d_model, chromo[1][0],chromo[4][1], chromo[5][1],chromo[6][1],chromo[8][1])\n",
    "        x = transformer_block1(x)\n",
    "        \n",
    "        transformer_block2 = TransformerBlock(d_model, chromo[1][1],chromo[4][1], chromo[5][1],chromo[6][1],chromo[8][1])\n",
    "        x = transformer_block2(x)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        transformer_block1 = TransformerBlock(d_model, chromo[1][0], chromo[4][2],chromo[5][2],chromo[6][2],chromo[8][2])\n",
    "        x = transformer_block1(x)\n",
    "        \n",
    "        transformer_block2 = TransformerBlock(d_model, chromo[1][1],chromo[4][2], chromo[5][2],chromo[6][2],chromo[8][2])\n",
    "        x = transformer_block2(x)\n",
    "        \n",
    "        transformer_block3 = TransformerBlock(d_model, chromo[1][2], chromo[4][2],chromo[5][2],chromo[6][2],chromo[8][2])\n",
    "        x = transformer_block3(x)\n",
    "    \n",
    "    #transformer_block2 = TransformerBlock(d_model, num_heads2, ff_dim21)\n",
    "    #x = transformer_block2(x)\n",
    "    x = GlobalAveragePooling1D()(x)   # dont edit this line\n",
    "    if chromo[3]==1:\n",
    "        \n",
    "        x = Dense(chromo[5][3], activation=chromo[4][3])(x)\n",
    "        x = Dropout(chromo[6])(x)\n",
    "   \n",
    "    outputs = Dense(2, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    #train\n",
    "    history = model.fit(x_train, y_train, batch_size=64, epochs=5, )\n",
    "\n",
    "    #test\n",
    "    results = model.evaluate(x_test, y_test, verbose=2)\n",
    "    return results\n",
    "    #for name, value in zip(model.metrics_names, results):\n",
    "       # print(\"%s: %.4f\" % (name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f3ec7f-6a7f-48b7-b193-5b24096ce9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c7c5f8-c512-4b1a-8e14-d47bf1b453ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layeroftrans = [1, 2, 3]\n",
    "num_attentionhead = [1, 2, 4, 8]\n",
    "num_hiddenfeedforward = [0, 1, 2]\n",
    "num_hiddenffn = [0, 1]\n",
    "name_actfunc = [\"relu\", \"sigmoid\"]\n",
    "num_neuron = [5, 10, 20, 30]\n",
    "prob_drop = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "d_model = [16, 32, 64, 128]\n",
    "norm_existance = [0, 1]\n",
    "\n",
    "Parameters=[num_layeroftrans,num_attentionhead,num_hiddenfeedforward,num_hiddenffn,name_actfunc,num_neuron,prob_drop,d_model,norm_existance]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be448c36-9eba-4bca-9aec-e64b4ac719b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual():  \n",
    "    def __init__(self, chromosome,Fitness):\n",
    "        self.chromosome = chromosome \n",
    "        self.fitness = Fitness\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e4b8aa-7edb-43d9-94e0-e075b8b8c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "def create_gnome():\n",
    "    num_layeroftrans = [1, 2, 3]\n",
    "    num_attentionhead = [1, 2, 4, 8]\n",
    "    num_hiddenfeedforward = [0, 1, 2]\n",
    "    num_hiddenffn = [0, 1]\n",
    "    name_actfunc = [\"relu\", \"sigmoid\"]\n",
    "    num_neuron = [5, 10, 20, 30]\n",
    "    prob_drop = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    d_model = [16, 32, 64, 128]\n",
    "    norm_existance = [0, 1]\n",
    "    n_layeroftrans = random.choice(num_layeroftrans)\n",
    "    n_attentionhead=[]\n",
    "    for i in range(n_layeroftrans):\n",
    "        n_attentionhead.append(random.choice(num_attentionhead))\n",
    "    n_hiddenfeedforward = []\n",
    "    for i in range(n_layeroftrans):\n",
    "        n_hiddenfeedforward.append(random.choice(num_hiddenfeedforward))\n",
    "    n_hiddenffn = random.choice (num_hiddenffn)\n",
    "    n_neuron =[]  \n",
    "    for i in n_hiddenfeedforward:\n",
    "        a=[]\n",
    "        for j in range(i):\n",
    "            a.append(random.choice(num_neuron))\n",
    "        n_neuron.append(a)\n",
    "    actfunc=[]\n",
    "    for i in n_hiddenfeedforward:\n",
    "        a=[]\n",
    "        for j in range(i):\n",
    "            a.append(random.choice(name_actfunc))\n",
    "        actfunc.append(a)  \n",
    "        \n",
    "    if  n_hiddenffn==1:   \n",
    "        a=[]\n",
    "        a.append(random.choice(name_actfunc))\n",
    "        actfunc.append(a)\n",
    "        \n",
    "        a=[]\n",
    "        a.append(random.choice(num_neuron))\n",
    "        n_neuron.append(a) \n",
    "\n",
    "    p_drop=[]\n",
    "    for i in n_hiddenfeedforward:\n",
    "        a=[]\n",
    "        for j in range(i):\n",
    "            a.append(random.choice(prob_drop))\n",
    "        p_drop.append(a)    \n",
    "    d_m = random.choice(d_model)\n",
    "    norm_exist=[]\n",
    "    for i in range(n_layeroftrans):\n",
    "        a=[]\n",
    "        for j in range(2):\n",
    "            a.append(random.choice(norm_existance))\n",
    "        norm_exist.append(a)    \n",
    "        \n",
    "    chromosome=[]\n",
    "    chromosome.append(n_layeroftrans)\n",
    "    chromosome.append(n_attentionhead)\n",
    "    chromosome.append(n_hiddenfeedforward)\n",
    "    chromosome.append(n_hiddenffn)\n",
    "    chromosome.append(actfunc)\n",
    "    chromosome.append(n_neuron)\n",
    "    chromosome.append(p_drop)\n",
    "    chromosome.append(d_m)\n",
    "    chromosome.append(norm_exist)\n",
    "    return chromosome\n",
    "\n",
    "def Eval_Fitness(chromo):\n",
    "    \n",
    "    outputs=[]\n",
    "    for i in range(iterations):\n",
    "        outputs.append(network(chromo))\n",
    "    sum1=0\n",
    "    for i in range(iterations):\n",
    "        sum1+=(outputs[i][1])\n",
    "    fitness=sum1/iterations\n",
    "    return fitness\n",
    "    \n",
    "def Binary_Tournament(population):\n",
    "    ParentsPool = []\n",
    "    for i in range(len(population)):\n",
    "        par1=random.choice(population)\n",
    "        par2=random.choice(population)\n",
    "        if par1.fitness>=par2.fitness:\n",
    "            ParentsPool.append( par1)\n",
    "        else:\n",
    "            ParentsPool.append( par2)\n",
    "    return ParentsPool    \n",
    "\n",
    "def UniformCrossover(par1,par2,Pc):\n",
    "    children=[]\n",
    "    child1=[]\n",
    "    child2=[]\n",
    "    for i in range(len(par1)):\n",
    "        r=random.random()\n",
    "        if r>=0 and r<Pc:\n",
    "            child1.append(par1.chromosome[i] )\n",
    "            child2.append(par2.chromosome[i])\n",
    "        else :\n",
    "            child2.append(par1.chromosome[i])\n",
    "            child1.append(par2.chromosome[i])\n",
    "    children.append(child1)\n",
    "    children.append(child2)\n",
    "    return children\n",
    "\n",
    "def mutation(chromo,Pm):\n",
    "    r=random.random()\n",
    "    if r>=0 and r<Pc:\n",
    "        idex=random.randrange(0,len(chromo))\n",
    "        chromo[idex]=random.choice(Parameters[idex])\n",
    "    return chromo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa1be99-f449-4ca1-bbdd-10bddaee733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations=10\n",
    "epochs=5\n",
    "pop_size=10\n",
    "iterations=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dbf2494-1d77-4055-afca-fb489b9e3ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 138s 338ms/step - loss: 0.4408 - accuracy: 0.7674\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 144s 367ms/step - loss: 0.2055 - accuracy: 0.9195\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 142s 362ms/step - loss: 0.1261 - accuracy: 0.9537\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 143s 365ms/step - loss: 0.0853 - accuracy: 0.9701\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 144s 368ms/step - loss: 0.0484 - accuracy: 0.9846\n",
      "782/782 - 69s - loss: 0.5668 - accuracy: 0.8448 - 69s/epoch - 89ms/step\n",
      "Epoch 1/5\n",
      "391/391 [==============================] - 159s 393ms/step - loss: 0.4113 - accuracy: 0.8006\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 150s 382ms/step - loss: 0.1953 - accuracy: 0.9241\n",
      "Epoch 3/5\n",
      "338/391 [========================>.....] - ETA: 19s - loss: 0.1186 - accuracy: 0.9589"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BORJ_I~1\\AppData\\Local\\Temp/ipykernel_8592/1910049989.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuralNetworkTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgnome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0msum1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\BORJ_I~1\\AppData\\Local\\Temp/ipykernel_8592/741569799.py\u001b[0m in \u001b[0;36mNeuralNetworkTransformer\u001b[1;34m(chromo)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m#train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m#test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "found = False\n",
    "gen=0\n",
    "population=[]\n",
    "# create initial population and calculate Fitness\n",
    "for i in range(pop_size):\n",
    "    gnome = create_gnome()\n",
    "    outputs=[]\n",
    "    for j in range(iterations):\n",
    "        outputs.append(NeuralNetworkTransformer(gnome))\n",
    "    sum1=0\n",
    "    for k in range(iterations):\n",
    "        sum1+=(outputs[k][1])\n",
    "    fitnes=sum1/iterations\n",
    "    population.append(Individual(gnome,fitnes))\n",
    "\n",
    "while (not found) :\n",
    "    if (gen==generations):\n",
    "        break\n",
    "\n",
    "    for g in population:\n",
    "        if g.fitness==1:\n",
    "            found=True\n",
    "            bestGene=g\n",
    "            break\n",
    "    if found==True:\n",
    "        print(bestGene.chromosome)\n",
    "        print(bestGene.Fitness)\n",
    "\n",
    "        break\n",
    "    \n",
    "    ParentsPool=[]\n",
    "    \n",
    "    for i in range(pop_size):\n",
    "        ParentsPool.append(Binary_Tournament(population))\n",
    "\n",
    "    random.shuffle(ParentsPool)\n",
    "    new_generation=[]\n",
    "    for i in range(int(pSize/2)):\n",
    "        par1=ParentsPool[i]\n",
    "        par2=ParentsPool[len(ParentsPool)-i-1]\n",
    "        Children=UniformCrossover(par1,par2,Pc)\n",
    "        Children[0]=MutationFunc(Children[0],Pm)\n",
    "        Children[1]=MutationFunc(Children[1],Pm)\n",
    "        fitnes0=Eval_Fitness(Children[0])\n",
    "        fitnes1=Eval_Fitness(Children[1])\n",
    "        population.append(Individual(Children[0],fitnes0))\n",
    "        population.append(Individual(Children[1],fitnes1))\n",
    "\n",
    "\n",
    "    population = sorted(population, key = lambda x:x.fitness)\n",
    "    bestGene=population[-1]\n",
    "    population=population[int(popSize/2):popSize]\n",
    "    random.shuffle(population)\n",
    "\n",
    "    generation = generation + 1\n",
    "\n",
    "if found==False:\n",
    "    print(bestGene.chromosome)\n",
    "    print(bestGene.Fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26437ea9-4776-4f43-82a4-15273548fafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b1948-c16b-4509-be54-9a1b0aab4b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6442eaf-683c-4417-b31f-e7a7072c1779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
